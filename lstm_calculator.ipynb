{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm calculator.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/glouwa/app-kandinsky-pattern-generator/blob/master/lstm_calculator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KR2slBmvw2W4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "outputId": "32a32238-060e-44db-aa7c-6346079988c2"
      },
      "source": [
        "!wget https://github.com/glouwa/app-kandinsky-pattern-generator/raw/master/lib.py"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-27 10:32:42--  https://github.com/glouwa/app-kandinsky-pattern-generator/raw/master/lib.py\n",
            "Resolving github.com (github.com)... 192.30.253.113\n",
            "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/glouwa/app-kandinsky-pattern-generator/master/lib.py [following]\n",
            "--2019-05-27 10:32:42--  https://raw.githubusercontent.com/glouwa/app-kandinsky-pattern-generator/master/lib.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5214 (5.1K) [text/plain]\n",
            "Saving to: ‘lib.py’\n",
            "\n",
            "\rlib.py                0%[                    ]       0  --.-KB/s               \rlib.py              100%[===================>]   5.09K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-05-27 10:32:42 (79.9 MB/s) - ‘lib.py’ saved [5214/5214]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxG-PcNlEbdH",
        "colab_type": "code",
        "outputId": "1a1862b5-4f41-4413-d00e-fa6f60200406",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from IPython.display import SVG\n",
        "from random import seed, randint\n",
        "from numpy import array, argmax\n",
        "import numpy as np\n",
        "import keras\n",
        "import lib"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwLm1Ty_INDi",
        "colab_type": "text"
      },
      "source": [
        "# Intro\n",
        "this tutorial is made to learn keras datagenerators.\n",
        "\n",
        "a small LSTM, procesing a input seqence of symbols and predicting a outputsymbol seqience is used snice data can be easyly generated.\n",
        "\n",
        "format sings are used to gernated x samples, phython eval is used on the X to generate the Y values.\n",
        "\n",
        "we a building a calculator.\n",
        "\n",
        "### Encoding\n",
        "a seqence of onehot encoded symbols s element alphabet, \n",
        "user defines input symbol seq len and output.\n",
        "\n",
        "X.shape = (samples,  in_seqlen,  alphalen)   \n",
        "Y.shape = (samples, out_seqlen,  alphalen)  \n",
        "\n",
        "### Predicting a Sample\n",
        "user will input a string, and want to read a string\n",
        "\n",
        "for prediction encode -> predict -> decode is neccesary \n",
        "  \n",
        "  \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmZ2iFt3Rrfi",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "f7c5e6b4-338c-4f22-8687-bbad381789d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "#@title Define context, sample dimensins { vertical-output: true }\n",
        "alphabet        = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '+', '-', '*', ' '] #@param {type:\"\"}\n",
        "\n",
        "in_seq_len      = 5 #@param {type:\"slider\", min:2, max:20, step:1}\n",
        "out_seq_len     = 4 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "  \n",
        "input_shape     = (in_seq_len,  len(alphabet))\n",
        "output_shape    = (out_seq_len, len(alphabet))\n",
        "\n",
        "print('input_shape:', input_shape, 'output_shape:', output_shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_shape: (5, 14) output_shape: (4, 14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APGh9hMKdxG0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "int_to_char    = dict((i, c) for i, c in enumerate(alphabet))  \n",
        "char_to_int    = dict((c, i) for i, c in enumerate(alphabet))\n",
        "\n",
        "to_onehot      = lambda val: [1 if val==i else 0 for i in range(len(alphabet))] \n",
        "\n",
        "sample_encode  = lambda string:      [to_onehot(char_to_int[char]) for char in string]\n",
        "sample_decode  = lambda hot: ''.join([int_to_char[argmax(step)] for step in hot])  \n",
        "\n",
        "pad_r         = lambda s,l: s + ''.join([' ' for _ in range(l-len(s))])  \n",
        "pad_l         = lambda s,l:     ''.join([' ' for _ in range(l-len(s))]) + s\n",
        "pad           = pad_l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CluOYlEJh9DU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Sample:  \n",
        "  def __init__(self, x, y):    \n",
        "    self.x = {\n",
        "        'str': x,\n",
        "        'hot': sample_encode(x) \n",
        "    }\n",
        "    self.y = {\n",
        "        'str': y,\n",
        "        'hot': sample_encode(y)\n",
        "    }      \n",
        "  def __str__(self):\n",
        "    return \"'{}' = '{}'\".format(self.x['str'], self.y['str'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMhTuzcoRTZI",
        "colab_type": "text"
      },
      "source": [
        "### Generating samples\n",
        "data is generated as sting expresssin, by a formatstring, which is filled with random numbers [0,  max_int] \n",
        "\n",
        "a saple is created with its various encodings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uobAU6VL5qcM",
        "colab_type": "code",
        "outputId": "c5f7c9d5-bce6-4098-8c70-77703c4ab145",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "#@title Create a sample by a given format string. calculate encodings. check encode/decode. { vertical-output: true }\n",
        "max_int         = 40 #@param {type:\"slider\", min:10, max:100, step:1}\n",
        "\n",
        "in_seq_format   = '{:d}*{:d}' #@param\n",
        "in_seq_vars     = 2 #@param\n",
        "out_seq_format  = '{:d}' #@param {type:\"raw\"}\n",
        "out_seq_vars    = 'eval in seq' #@param {type:\"raw\"}\n",
        "\n",
        "formatparams    = [in_seq_format, in_seq_len, out_seq_len, out_seq_format, out_seq_len]\n",
        "\n",
        "#def SampleFromFormat(xt, in_seq_len, c, yt, out_seq_len):\n",
        "#  xstr = xt.format(*[randint(0, max_int) for _ in range(c)])\n",
        "#  ystr = yt.format(eval(xstr))\n",
        "#  xstr = pad(xstr, in_seq_len)\n",
        "#  ystr = pad(ystr, out_seq_len)\n",
        "#  return Sample(xstr, ystr)\n",
        "\n",
        "def SampleFromFormat(in_format, in_seq_len, var_count, out_format, out_seq_len):\n",
        "    rand_arr = [randint(0, max_int) for _ in range(var_count)]\n",
        "    x_exp_str = in_format.format(*rand_arr)\n",
        "    y_val_str = out_format.format(eval(x_exp_str))\n",
        "    xstr = pad(x_exp_str, in_seq_len)\n",
        "    ystr = pad(y_val_str, out_seq_len)\n",
        "    return Sample(xstr, ystr)\n",
        "\n",
        "s = SampleFromFormat(*formatparams)\n",
        "print(\"generated string:\", s)\n",
        "print(\"encoded and back: '{}' = '{}'\".format(sample_decode(s.x['hot']), sample_decode(s.y['hot'])))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "generated string: '19*39' = ' 741'\n",
            "encoded and back: '19*39' = ' 741'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkwRUdjTZXS4",
        "colab_type": "text"
      },
      "source": [
        "# Ok, we have a Sample class - now lets make a Keras DataGenerator\n",
        "\n",
        "create some samples, and extracts the enhot encoded seqences X and y as a numpy arrays\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njkKyHsRAqGq",
        "colab_type": "code",
        "outputId": "c55fa666-aa4f-4302-ee9a-a4316b07aba4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "#@title Now lets generate a set of such Samples { vertical-output: true }\n",
        "def generate_data(n_samples):  \n",
        "  X = list()\n",
        "  y = list()\n",
        "  for i in range(0, n_samples):\n",
        "    s = SampleFromFormat(*formatparams) \n",
        "    X.append(s.x['hot'])\n",
        "    y.append(s.y['hot'])\n",
        "    \n",
        "  return array(X), array(y) \n",
        "\n",
        "generate_data(1)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
              "         [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]]]),\n",
              " array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              "         [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgCcCiBz4mFt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Data Generators are the adapter to keras{ vertical-output: true }\n",
        "batch_size      = 1 #@param {type:\"slider\", min:1, max:300, step:10}\n",
        "training_size   = 3200 #@param {type:\"slider\", min:1000, max:3200, step:100}\n",
        "validation_size = 400 #@param {type:\"slider\", min:10, max:500, step:10}\n",
        "test_size       = 400 #@param {type:\"slider\", min:10, max:500, step:10}\n",
        "\n",
        "class DataGenerator(keras.utils.Sequence):\n",
        "    'Generates kandinsky data for Keras'\n",
        "    def __init__(self, samples=1000, batch_size=32, in_dim=(), out_dim=()):        \n",
        "        self.n_samples = samples\n",
        "        self.batch_size = batch_size\n",
        "        self.in_dim = in_dim                \n",
        "        self.out_dim = out_dim\n",
        "        print('DataGenerator: samples=', self.n_samples, \"batchsize=\", \n",
        "              self.batch_size, \"len=\", int(np.floor(self.n_samples / self.batch_size)))\n",
        "        \n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'        \n",
        "        return int(np.floor(self.n_samples / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):        \n",
        "        #indexes = self.indexes[index * self.batch_size : (index+1) * self.batch_size]        \n",
        "        #list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
        "        \n",
        "        X = np.empty((self.batch_size, *self.in_dim))\n",
        "        y = np.empty((self.batch_size), dtype=int)        \n",
        "        #print(\"Xy shapes: \", X.shape, y.shape)\n",
        "        X, y = generate_data(self.batch_size)\n",
        "        #print(\"Xy shapes: \", X.shape, y.shape)\n",
        "        return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPxl898kUoh2",
        "colab_type": "code",
        "outputId": "3a78d860-f420-42ab-d331-c65a33c77a51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        }
      },
      "source": [
        "#@title Train/Test/Validate Generators { vertical-output: true, output-height: 200 }\n",
        "params = {\n",
        "    'batch_size': batch_size,\n",
        "    'in_dim': input_shape,    \n",
        "    'out_dim': output_shape\n",
        "}\n",
        "\n",
        "training_generator =   DataGenerator(samples=training_size, **params)\n",
        "validation_generator = DataGenerator(samples=validation_size, **params)\n",
        "test_generator =       DataGenerator(samples=test_size, **params)\n",
        "\n",
        "view_generator =       DataGenerator(samples=1, **params)\n",
        "view_generator[0][0].shape, view_generator[0][1].shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DataGenerator: samples= 3200 batchsize= 1 len= 3200\n",
            "DataGenerator: samples= 400 batchsize= 1 len= 400\n",
            "DataGenerator: samples= 400 batchsize= 1 len= 400\n",
            "DataGenerator: samples= 1 batchsize= 1 len= 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1, 5, 14), (1, 4, 14))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBwHpPBDZAEQ",
        "colab_type": "text"
      },
      "source": [
        "# Data is ready - Time for the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1D-QkWHxdibe",
        "colab_type": "code",
        "outputId": "d15fc097-c158-44e0-d388-a39f77b00fa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 798
        }
      },
      "source": [
        "#@title Any LSTM configuration { vertical-output: true, output-height: 200 }\n",
        "loss         = \"categorical_crossentropy\" #@param [\"categorical_crossentropy\", \"whatever\"]\n",
        "optimizer    = \"adam\"                     #@param [\"adam\" ,\"other\"]\n",
        "main_metric  = \"accuracy\"                 #@param [\"accuracy\"]\n",
        "n1           = 100 #@param {type:\"slider\", min:1, max:500, step:1}\n",
        "n2           = 50 #@param {type:\"slider\", min:1, max:500, step:1}\n",
        "  \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, TimeDistributed, RepeatVector\n",
        "  \n",
        "model = Sequential()\n",
        "model.add(LSTM(n1, input_shape=input_shape))\n",
        "model.add(RepeatVector(out_seq_len))\n",
        "model.add(LSTM(n2, return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(len(alphabet), activation='softmax')))\n",
        "model.compile(loss=loss, optimizer=optimizer, metrics=[main_metric])\n",
        "\n",
        "print(model.summary())\n",
        "SVG(keras.utils.vis_utils.model_to_dot(model).create(prog='dot', format='svg'))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 100)               46000     \n",
            "_________________________________________________________________\n",
            "repeat_vector_1 (RepeatVecto (None, 4, 100)            0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 4, 50)             30200     \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 4, 14)             714       \n",
            "=================================================================\n",
            "Total params: 76,914\n",
            "Trainable params: 76,914\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"337pt\" viewBox=\"0.00 0.00 334.00 337.00\" width=\"334pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 333)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-333 330,-333 330,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140241305399248 -->\n<g class=\"node\" id=\"node1\">\n<title>140241305399248</title>\n<polygon fill=\"none\" points=\"112,-219.5 112,-255.5 214,-255.5 214,-219.5 112,-219.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163\" y=\"-233.8\">lstm_1: LSTM</text>\n</g>\n<!-- 140240902739952 -->\n<g class=\"node\" id=\"node2\">\n<title>140240902739952</title>\n<polygon fill=\"none\" points=\"67.5,-146.5 67.5,-182.5 258.5,-182.5 258.5,-146.5 67.5,-146.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163\" y=\"-160.8\">repeat_vector_1: RepeatVector</text>\n</g>\n<!-- 140241305399248&#45;&gt;140240902739952 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140241305399248-&gt;140240902739952</title>\n<path d=\"M163,-219.4551C163,-211.3828 163,-201.6764 163,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"166.5001,-192.5903 163,-182.5904 159.5001,-192.5904 166.5001,-192.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140240902081000 -->\n<g class=\"node\" id=\"node3\">\n<title>140240902081000</title>\n<polygon fill=\"none\" points=\"112,-73.5 112,-109.5 214,-109.5 214,-73.5 112,-73.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163\" y=\"-87.8\">lstm_2: LSTM</text>\n</g>\n<!-- 140240902739952&#45;&gt;140240902081000 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140240902739952-&gt;140240902081000</title>\n<path d=\"M163,-146.4551C163,-138.3828 163,-128.6764 163,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"166.5001,-119.5903 163,-109.5904 159.5001,-119.5904 166.5001,-119.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140240848272352 -->\n<g class=\"node\" id=\"node4\">\n<title>140240848272352</title>\n<polygon fill=\"none\" points=\"0,-.5 0,-36.5 326,-36.5 326,-.5 0,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163\" y=\"-14.8\">time_distributed_1(dense_1): TimeDistributed(Dense)</text>\n</g>\n<!-- 140240902081000&#45;&gt;140240848272352 -->\n<g class=\"edge\" id=\"edge4\">\n<title>140240902081000-&gt;140240848272352</title>\n<path d=\"M163,-73.4551C163,-65.3828 163,-55.6764 163,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"166.5001,-46.5903 163,-36.5904 159.5001,-46.5904 166.5001,-46.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140240902079376 -->\n<g class=\"node\" id=\"node5\">\n<title>140240902079376</title>\n<polygon fill=\"none\" points=\"98.5,-292.5 98.5,-328.5 227.5,-328.5 227.5,-292.5 98.5,-292.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163\" y=\"-306.8\">140240902079376</text>\n</g>\n<!-- 140240902079376&#45;&gt;140241305399248 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140240902079376-&gt;140241305399248</title>\n<path d=\"M163,-292.4551C163,-284.3828 163,-274.6764 163,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"166.5001,-265.5903 163,-255.5904 159.5001,-265.5904 166.5001,-265.5903\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ad1fTxY_EDSE",
        "colab_type": "code",
        "outputId": "1c863c1e-8bfe-4bca-f4a4-40a68ae15ce7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "#@title Training { vertical-output: true }\n",
        "%%time\n",
        "epochs             = 100 #@param {type:\"slider\", min:2, max:500, step:1}\n",
        "use_multprocessing = True #@param {type:\"boolean\"}\n",
        "workers            = 16 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "verbose            = 0 #@param {type:\"slider\", min:0, max:5, step:1}\n",
        "\n",
        "history = model.fit_generator(\n",
        "  generator = training_generator,\n",
        "  validation_data = validation_generator,                    \n",
        "  epochs = epochs,\n",
        "  steps_per_epoch = 100,\n",
        "  use_multiprocessing = use_multprocessing,\n",
        "  workers = workers,\n",
        "  verbose = verbose,\n",
        "  )#callbacks = [keras.callbacks.EarlyStopping(monitor='val_acc', sensible=2)])\n",
        "\n",
        "lib.plot_history(history)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCnvl0KgZMbY",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTBaD3DTd0wy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Show some errors by sample { vertical-output: true }\n",
        "max_errors = 18 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "\n",
        "# evaluate on some new patterns\n",
        "X, y = generate_data(1000)\n",
        "print(X.shape, y.shape)\n",
        "\n",
        "predicted = model.predict(X, verbose=1)\n",
        "\n",
        "expected =  [sample_decode(s) for s in y]\n",
        "predicted = [sample_decode(s) for s in predicted]\n",
        "\n",
        "c = 0\n",
        "for i in range(0, len(result)):\n",
        "  if expected[i] != predicted[i]:\n",
        "    c = c + 1\n",
        "    if c < max_errors:\n",
        "      print('Expected=%s, Predicted=%s' % (expected[i], predicted[i]))  \n",
        "      \n",
        "print(\"expected != predicted Count:\", c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAu9-qxLJjUy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Test Metrics { vertical-output: true }\n",
        "\"Accuracy %s\" % model.evaluate_generator(test_generator)[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uIMd8Wgs7VC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Use the trained Model  { vertical-output: true }\n",
        "def calculate(inp):\n",
        "  print(inp, '=')\n",
        "  padded = pad(inp, in_seq_len)  \n",
        "  X = array([sample_encode(padded)])  \n",
        "  result = model.predict(X)\n",
        "  return sample_decode(result[0])\n",
        "\n",
        "print(calculate('3*7'), \"should be\", 3*7)\n",
        "print(calculate('13*18'), \"should be\", 13*18)\n",
        "print(calculate('3*43'), \"(extrapolated) should be\", 3*43)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}